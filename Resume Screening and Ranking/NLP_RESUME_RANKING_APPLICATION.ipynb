{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "0a9e81b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.high_level import extract_text\n",
    "\n",
    "#Loading Libraries\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "015a8613",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df=pd.read_csv('UpdatedResumeDataSet.csv' ,encoding='utf-8')\n",
    "# for cat in [\"Hadoop\",\"ETL Developer\",\"HR\",\"Advocate\",\"Arts\",\"Testing\",'PMO',\"Operations Manager\",\"SAP Developer\"]:\n",
    "#     mask=df.Category!=cat\n",
    "#     df=df[mask]\n",
    "\n",
    "# resumeDataSet =df.copy()\n",
    "# #EDA\n",
    "# plt.figure(figsize=(15,15))\n",
    "# plt.xticks(rotation=90)\n",
    "# sns.countplot(y=\"Category\", data=resumeDataSet)\n",
    "# plt.savefig('../jobcategory_details.png')\n",
    "# #Pie-chart\n",
    "# targetCounts = resumeDataSet['Category'].value_counts().reset_index()['Category']\n",
    "# targetLabels  = resumeDataSet['Category'].value_counts().reset_index()['index']\n",
    "# # Make square figures and axes\n",
    "# plt.figure(1, figsize=(25,25))\n",
    "# the_grid = GridSpec(2, 2)\n",
    "# plt.subplot(the_grid[0, 1], aspect=1, title='CATEGORY DISTRIBUTION')\n",
    "# source_pie = plt.pie(targetCounts, labels=targetLabels, autopct='%1.1f%%', shadow=True, )\n",
    "# plt.savefig('../category_dist.png')\n",
    "# #Data Preprocessing\n",
    "# def cleanResume(resumeText):\n",
    "#     resumeText = re.sub('httpS+s*', ' ', resumeText)  # remove URLs\n",
    "#     resumeText = re.sub('RT|cc', ' ', resumeText)  # remove RT and cc\n",
    "#     resumeText = re.sub('#S+', '', resumeText)  # remove hashtags\n",
    "#     resumeText = re.sub('@S+', '  ', resumeText)  # remove mentions\n",
    "#     resumeText = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,-./:;<=>?@[]^_`{|}~\"\"\"), ' ', resumeText)  # remove punctuations\n",
    "#     resumeText = re.sub(r'[^x00-x7f]',r' ', resumeText) \n",
    "#     resumeText = re.sub('s+', ' ', resumeText)  # remove extra whitespace\n",
    "#     return resumeText\n",
    "# resumeDataSet['cleaned_resume'] = resumeDataSet.Resume.apply(lambda x: cleanResume(x))\n",
    "# var_mod = ['Category']\n",
    "# le = LabelEncoder()\n",
    "# for i in var_mod:\n",
    "#     resumeDataSet[i] = le.fit_transform(resumeDataSet[i])\n",
    "# requiredText = resumeDataSet['cleaned_resume'].values\n",
    "# requiredTarget = resumeDataSet['Category'].values\n",
    "# word_vectorizer = TfidfVectorizer(\n",
    "#     analyzer='word', \n",
    "#     sublinear_tf=True,\n",
    "#     strip_accents='unicode',\n",
    "#     token_pattern=r'\\w{1,}',\n",
    "#     ngram_range=(1, 1),\n",
    "#     max_features=10000)\n",
    "# word_vectorizer.fit(requiredText)\n",
    "# WordFeatures = word_vectorizer.transform(requiredText)\n",
    "# #Model Building\n",
    "# X_train,X_test,y_train,y_test = train_test_split(WordFeatures,requiredTarget,random_state=0, test_size=0.2)\n",
    "# # print(X_train.shape)\n",
    "# # print(X_test.shape)\n",
    "# clf = OneVsRestClassifier(KNeighborsClassifier())\n",
    "# clf.fit(X_train, y_train)\n",
    "# prediction = clf.predict(X_test)\n",
    "# #Results\n",
    "# print('Accuracy of KNeighbors Classifier on training set: {:.2f}'.format(clf.score(X_train, y_train)))\n",
    "# print('Accuracy of KNeighbors Classifier on test set: {:.2f}'.format(clf.score(X_test, y_test)))\n",
    "# # print(\"n Classification report for classifier %s:n%sn\" % (clf, metrics.classification_report(y_test, prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83cb176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resumeDataSet.drop(['Resume'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e9a90705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resume=resumeDataSet[[\"Category\",\"cleaned_resume\"]]\n",
    "# resm_df=resumeDataSet[[\"cleaned_resume\",\"Category\"]]\n",
    "# resm_df.head()\n",
    "\n",
    "# ziped=zip((resm_df.Category.tolist()),(df.Category.tolist()))\n",
    "# print(len(df.Category.tolist()),len(resm_df.Category.tolist()))\n",
    "# dictionary=dict(ziped)\n",
    "# dictionary.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "d4b82deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the file pathC:/Users/sefineh/Downloads/Sefineh's Resume (1).pdf\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dictionary.pickel'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2496/2055717631.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mfile_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Enter the file path\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mtakeInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2496/2055717631.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mfile_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Enter the file path\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0mtakeInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2496/2055717631.py\u001b[0m in \u001b[0;36mtakeInput\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mtext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mvector_form\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mword_vectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0moutput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvector_form\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2496/2055717631.py\u001b[0m in \u001b[0;36mprediction\u001b[1;34m(model, resume)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mresume\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mloaded_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"dictionary.pickel\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mloaded_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileName\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0moutput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mloaded_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mloaded_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresume\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dictionary.pickel'"
     ]
    }
   ],
   "source": [
    "def prediction(model,resume):\n",
    "    loaded_dict=pickle.load(open(\"dictionary.pickel\",\"rb\"))\n",
    "    loaded_model = pickle.load(open(fileName, 'rb'))\n",
    "    try:\n",
    "        output=loaded_dict[loaded_model.predict(resume)[0]]\n",
    "        return output\n",
    "    except:\n",
    "        return \n",
    "\n",
    "pathName=\"C:/Users/sefineh/Downloads/Sefineh's Resume (1).pdf\"\n",
    "def pdfExtracter(pathName):\n",
    "    return extract_text(pathName)\n",
    "\n",
    "def takeInput(file_path):\n",
    "    \n",
    "    text=pdfExtracter(file_path)\n",
    "    text=cleanResume(text)\n",
    "    text=np.array([text])\n",
    "    vector_form=word_vectorizer.transform(text)\n",
    "    output=prediction(clf,vector_form)\n",
    "    print(output)\n",
    "def main():    \n",
    "    file_path=input(\"Enter the file path\")\n",
    "    takeInput(file_path)\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "2d87f2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# import os\n",
    "# if not os.path.exists(\"mod\"):\n",
    "#     os.mkdir(\"./mod\")\n",
    "fileName=\"./mod/model.sav\"\n",
    "pickle.dump(clf,open(fileName,\"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "8bba8486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_model = pickle.load(open(fileName, 'rb'))\n",
    "# result = loaded_model.score(X_test, Y_test)\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "8416b9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(word_vectorizer, open(\"tfidf.pickle\", \"wb\"))\n",
    "# pickle.dump(X_test, open(\"X_test.pickle\", \"wb\"))\n",
    "# pickle.dump(y_test, open(\"y_test.pickle\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "f9cd3444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(dictionary,open(\"dictionary.pickel\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "b9a655df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b25ba8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36917460",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41a6eed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5f55f43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a228d58b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036ed458",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacc1722",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c8baa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878fe48a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
